---
title: "Model Comparison"
author: "Sarah Killcoyne"
date: "2 October 2017"
output: 
  html_document:
    fig_height: 5
    fig_width: 5
    toc: yes
    toc_depth: 4

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, error = T)

library(tidyverse)
library(BarrettsProgressionRisk)

library(ggrepel)
#library(GGally)
library(kableExtra)
library(reshape2)
library(gridExtra)
#library(CoxHD)
library(RColorBrewer)

library(OACUtils)

source('lib/load_patient_metadata.R')
#source('lib/cv-pt-glm.R')
source('lib/common_plots.R')


data = '~/Data/BarrettsProgressionRisk/Analysis/models_5e6_all/'
info.dir = '~/Data/BarrettsProgressionRisk/QDNAseq'

patient.file = list.files(info.dir, pattern='All_patient_info.xlsx', recursive=T, full.names=T)
demo.file = list.files(info.dir, pattern='Demographics_full.xlsx', recursive=T, full.names=T)

if (length(patient.file) != 1 | length(demo.file) != 1)
  stop(paste("Missing/too many patient info file(s) in", info.dir))

all.patient.info = read.patient.info(patient.file, demo.file, set='All')$info

patient.info = all.patient.info %>% dplyr::filter(Set == 'Training')

patient.info = arrange(patient.info, Status, Hospital.Research.ID, Endoscopy.Year, Pathology)
sum.patient.data = as_tibble(summarise.patient.info(patient.info))

```


# Model performance

Per alpha value and kb segment size the overall performance per cross-validated model.  While 15kb is consistently the best at alpha = 0.9 the performance for 50kb or 100kb is about 66% for both.

```{r, fig.width=8,fig.height=7}
dir.create('plots/parameters')
kb.models = list.files(data)

kb.dirnames = grep('kb', list.files(data,full.names = T), value=T)

kb.perf = do.call(bind_rows, lapply(kb.dirnames, function(f) {
  load(paste0(f,'/all.pt.alpha.Rdata'),verbose=F)
  nonz = names(which(sapply(performance.at.1se, nrow) > 0))
# do.call(bind_rows,lapply(coefs, function(df){
#   tibble(n=nrow(df), mean.stability=mean(rowSums(df[,-1])/50), sd.stability=sd(rowSums(df[,-1])/50) )
# })) %>% mutate(alpha=names(coefs), kb=basename(f))
  do.call(bind_rows, performance.at.1se) %>% 
    mutate(alpha=nonz, kb = basename(f), n.coefs=sapply(coefs[nonz], nrow)) %>% 
    dplyr::select(mean, sme, `lambda-1se`, alpha, n.coefs, kb) 
  
}))
kb.perf = kb.perf %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T)) %>% arrange(kb, alpha)

kb.perf %>% dplyr::select(-`lambda-1se`) %>% write_tsv('plots/exfig9a.tsv')

p = ggplot(kb.perf, aes(kb, mean, fill=kb)) + facet_grid(~alpha) + ylim(0,1) + 
  geom_col() + geom_errorbar(aes(ymin=mean-sme, ymax=mean+sme), col='grey39', width=0.2) + 
  #geom_text(aes(label=n.coefs, y = 0.01)) + 
  scale_fill_brewer(palette='Set1') + 
  labs(x='',y='classification accuracy', title = 'Cross-Validation Classification Accuracy', subtitle='Alpha values:') +
  theme_minimal() + theme(text = element_text(size=12), axis.text.x  = element_text(hjust = 0.5, angle=90))
p
ggsave(filename='plots/parameters/cv_accuracy.png', plot = p, width = 6, height = 6, units = 'in', dpi = 300)
```


# ROC

## LOO Discovery

Finally, I generate a ROC for each of the leave-one out prediction sets. Here again the AUC is best at 15kb.  However, 100kb is the best of the larger bin sizes.  The tradeoff here is that the TPR is not as good as 15kb or 50kb (given the threshold selected by the ROC).  The FPR is the highest in the 50kb bins.


```{r fig.height=7, fig.width=8}
threshold = 'best'
rc9 = do.call(bind_rows, lapply(kb.dirnames, function(f) {
  load(paste0(f,'/loo_0.9.Rdata'),verbose=F)
  roc = pROC::roc(Status ~  Prediction, data=pg.samp, auc=T, ci=T, of='thresholds',quiet=T)

  bind_cols(
    as_tibble(pROC::ci.auc(roc)) %>% mutate(m = c('auc.low', 'auc', 'auc.high')) %>% spread(m,value),
    as_tibble(data.frame(pROC::ci.coords(roc, threshold, transpose=F))) %>% dplyr::select(-matches('threshold')) %>% 
      set_names(c('specificity.low', 'specificity', 'specificity.high', 'sensitivity.low', 'sensitivity', 'sensitivity.high')) ) %>%
    mutate(kb = basename(f))
})) 

rc9 = rc9 %>%  mutate(kb = factor(kb,levels=c('15kb','50kb','100kb','500kb'), ordered=T)) %>% arrange(kb) 

df = rc9 %>% dplyr::select(matches('auc|kb'))
pos = position_dodge(width=0.9)
p = ggplot() + 
  geom_bar(data=df, aes(x=kb, y=auc, group=kb, fill=kb), stat='identity', position = pos, show.legend = F) + 
  geom_errorbar(data=df, aes(x=kb, ymin=auc.low, ymax=auc.high, group=kb), position = pos, width=0.2, color='grey39') +
  scale_fill_brewer(palette='Set1') + 
  scale_y_continuous(expand=c(0,0), limits=c(0,1)) + 
  labs(title='', subtitle = 'alpha=0.9', x='AUC', y='%') + 
  theme_minimal() + theme(text=element_text(size=12), axis.text.x = element_text(angle=45, hjust=1))

df = rc9 %>% dplyr::select(matches('sensitivity|kb'))
p1 = ggplot() + 
  geom_bar(data=df, aes(x=kb, y=sensitivity, group=kb, fill=kb), stat='identity', position = pos, show.legend = F) + 
  geom_errorbar(data=df, aes(x=kb, ymin=sensitivity.low, ymax=sensitivity.high, group=kb), position = pos, width=0.2, color='grey39') +
  scale_fill_brewer(palette='Set1') + 
  scale_y_continuous(expand=c(0,0), limits=c(0,1)) + 
  labs(title='', subtitle = '', x='TPR', y='') + 
  theme_minimal() + theme(text=element_text(size=12), axis.text.x = element_text(angle=45, hjust=1), axis.text.y = element_blank())

df = rc9 %>% dplyr::select(matches('specificity|kb'))
p2 = ggplot() + 
  geom_bar(data=df, aes(x=kb, y=1-specificity, group=kb, fill=kb), stat='identity', position = pos, show.legend = F) + 
  geom_errorbar(data=df, aes(x=kb, ymin=1-specificity.low, ymax=1-specificity.high, group=kb), position = pos, width=0.2, color='grey39') +
  scale_fill_brewer(palette='Set1') + 
  scale_y_continuous(expand=c(0,0), limits=c(0,1)) + 
  labs(title='', subtitle = '', x='FPR', y='') + 
  theme_minimal() + theme(text=element_text(size=12), axis.text.x = element_text(angle=45, hjust=1), axis.text.y = element_blank())

rc9 %>% dplyr::rename('auc.ci.high'='auc.high', 'auc.ci.low'='auc.low') %>% write_tsv('plots/exfig9b.tsv')

grid.arrange(p,p1,p2,nrow=1)
ggsave(filename='plots/parameters/training_kb_auc.png', plot = grid.arrange(p,p1,p2,nrow=1,top='Discovery ROC'), width = 6, height = 6, units = 'in', dpi = 300)
# rc9 = rc9 %>% set_names(c('Threshold','FPR','TPR','AUC','AUC.CI.Low','AUC.CI.High','kb')) %>% 
#   mutate(kb = factor(kb,levels=c('15kb','50kb','100kb','500kb'), ordered=T), FPR = 1-FPR) %>% arrange(kb) %>%
#   dplyr::select(-Threshold)
```

## Validation predicted on corresponding model

```{r fig.height=7, fig.width=8}
val.file = '~/Data/BarrettsProgressionRisk/QDNAseq/validation/sWGS_validation_batches.xlsx'
sheets = readxl::excel_sheets(val.file)[8:14]

pastefun<-function(x) {
  if ( !grepl('SLX-', x) ) x = paste0('SLX-',x)
  return(x)
}

val.info = do.call(bind_rows, lapply(sheets, function(s) {
  readxl::read_xlsx(val.file, s) %>% dplyr::select(`Hospital Research ID`, matches('Status'), `Block ID`,`Sample Type`, `SLX-ID`, `Index Sequence`, Pathology, Cohort, Batch, matches('Collection|Notes')) %>% 
    dplyr::filter(!is.na(`SLX-ID`)) %>% mutate_at(vars(`SLX-ID`, `Block ID`), list(as.character)) 
})) %>% mutate(Samplename = paste(`SLX-ID`,`Index Sequence`, sep='.')) %>% 
  rowwise %>% mutate_at(vars(`SLX-ID`), list(pastefun) ) %>% ungroup %>% 
  mutate(
  #`Hospital Research ID` = str_replace_all( str_remove_all(`Hospital Research ID`, " "), '/', '_'), 
  `Index Sequence` = str_replace_all(`Index Sequence`, 'tp', ''),
  Samplename = paste(`SLX-ID`,`Index Sequence`,sep='.')
  )

vdir = '~/Data/BarrettsProgressionRisk/Analysis/validation/pcf_perPatient'

val.preds = purrr::map(list.files(vdir, full.names=T), function(dir) {
  print(dir)
  do.call(bind_rows, purrr::map(list.files(paste0(dir,'/predictions_5e6_all/0.9'), 'predictions.tsv', full.names = T, recursive = T), function(f) {
    pd = read_tsv(f, col_types = 'cddcccDcccc') %>% dplyr::select(`Hospital Research ID`, everything())
    left_join(pd, val.info %>% dplyr::select(`Hospital Research ID`, Status, Samplename, Cohort), by=c('Hospital Research ID', 'Sample'='Samplename')) %>% 
      mutate(kb = basename(dir)) %>% mutate(Risk = factor(Risk, levels=c('Low','Moderate','High'), ordered=T)) 
  }))
})
names(val.preds) = list.files(vdir)

val.auc = do.call(bind_rows, purrr::map(val.preds, function(kb) {
  roc = pROC::roc(Status ~ Probability, data=kb, auc=T, ci=T, of='thresholds', quiet=T)
  #pROC::coords(roc, "best", transpose=F) %>% mutate( auc = as.numeric(pROC::auc(roc)), kb = unique(kb$kb) )
  
  bind_cols(
    as_tibble(pROC::ci.auc(roc)) %>% mutate(m = c('auc.low', 'auc', 'auc.high')) %>% spread(m,value),
    as_tibble(data.frame(pROC::ci.coords(roc, threshold, transpose=F))) %>% dplyr::select(-matches('threshold')) %>% 
      set_names(c('specificity.low', 'specificity', 'specificity.high', 'sensitivity.low', 'sensitivity', 'sensitivity.high')) ) %>%
    mutate(kb = unique(kb$kb))
}))

# val.auc = val.auc %>% set_names(c('Threshold','FPR','TPR','AUC','kb')) %>% 
#   mutate(kb = factor(kb,levels=c('15kb','50kb','100kb','500kb'), ordered=T), FPR = 1-FPR) %>% arrange(kb) %>%
#   dplyr::select(-Threshold)
# 
# ggplot(melt(val.auc, id.vars='kb'), aes(variable, value, group=kb)) + ylim(0,1) +
#   geom_bar(aes(fill=kb), stat='identity', position='dodge') + 
#   geom_text(aes(label=round(value,2)), position=position_dodge(width=1)) + 
#   scale_fill_brewer(palette='Set1') + 
#   labs(title='Validation ROC (alpha=0.9)', x='', y='%') + theme_minimal()
```

## Side-by-side

```{r fig.height=7, fig.width=8}
aucs = bind_rows(rc9 %>% mutate(Cohort = 'Discovery'), val.auc %>% mutate(Cohort = 'Validation'))
aucs = aucs %>% dplyr::select(matches('auc|kb|Cohort')) %>% dplyr::rename('AUC'='auc') %>% 
  mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))

aucs %>% dplyr::rename('AUC.CI.high'= 'auc.high', 'AUC.CI.low'='auc.low')  %>% write_tsv('plots/exfig9c.tsv')

p = ggplot(aucs, aes(kb, AUC, group=Cohort)) + ylim(0,1) + 
  geom_bar(aes(fill=Cohort), stat='identity', position=pos) + 
  geom_errorbar(aes(ymin=auc.low, ymax=auc.high), width=0.2, color='grey39', stat='identity', position=pos) +
  geom_text(aes(label=round(AUC,2), y=auc.low-0.05), position=position_dodge(width=1)) + 
  scale_fill_brewer(palette='Set1') + 
  labs(title='AUC discovery & validation', x='', y='AUC') + 
  theme_minimal() + theme(text = element_text(size=12))
p
ggsave(filename='plots/parameters/tv_auc_kb_compare.png', plot = p, width = 6, height = 6, units = 'in', dpi = 300)

```

# Discovery LOO Performance

The leave-one out analysis uses the models for alpha=0.9. 

```{r, echo=F}
minR = 0.3
maxR = 0.5
```


Cutoffs are  `r minR` < P > `r maxR`

```{r, fig.width=8, fig.height=12}
ft.fun<-function(NP,P) {
 f = chisq.test(rbind(cbind(NP,P),table(sum.patient.data$Status)))
 cbind.data.frame('p.value'=round(f$p.value, 4))
}

pred.conf<-function(df) {
  df = df %>% mutate(quants = cut(Prediction, breaks=seq(0,1,0.1), include.lowest = T))
  qts = df %>% group_by(quants, Status) %>% dplyr::summarise(n=length(Status) ) %>% ungroup %>%
    spread(Status, n) %>%  mutate_all(~replace_na(.,0)) %>% 
    left_join(df %>% dplyr::group_by(quants) %>% 
                dplyr::summarise ( 'mn'=mean(Prediction), 'sd'=sd(Prediction) ), by='quants') 

  pred.confidence = qts %>% dplyr::group_by(quants) %>% 
    dplyr::mutate( 'P.ratio'=P/sum(NP,P), 'p.value'=ft.fun(NP,P)$p.value, 'conf'=ifelse(p.value < 0.05, '*', '') ) %>% 
    separate(quants, c('r1','r2'), ',', remove = F) %>% 
    mutate_at(vars('r1','r2'), list(sub), pattern='\\[|\\]|\\(', replacement='') %>% 
    mutate_at(vars(r1,r2), as.double) 
  
  # set cutoffs
  pred.confidence = pred.confidence %>% ungroup %>% rowwise %>% mutate(Risk = 'Moderate') %>%
    mutate(Risk = ifelse(r2 <= minR, 'Low',Risk)) %>% mutate(Risk = ifelse(r1 >= maxR, 'High',Risk)) 

  pred.confidence = bind_cols(pred.confidence, 
                            data.frame(ci.low=qbeta(0.025, shape1=pred.confidence$P+.5, shape2 = pred.confidence$NP+.5),
                                         ci.high=qbeta(0.975, shape1=pred.confidence$P+.5, shape2 = pred.confidence$NP+.5)))
  return(pred.confidence)
}
```

```{r, fig.width=10,fig.height=7, eval=F}
## 0.5
loo.pred.confidence = purrr::map( list.files(data,full.names = T), function(f) {
  print(f)
  load(paste0(f,'/loo_0.5.Rdata'),verbose=F)
  suppressWarnings(pred.conf(pg.samp)) %>% mutate(kb = basename(f))
}) 
names(loo.pred.confidence) = basename(list.files(data,full.names = T))

plist = lapply(loo.pred.confidence, function(lpf) {
  BarrettsProgressionRisk::showPredictionCalibration(lpf %>% dplyr::rename('perc' = 'P.ratio') ) + labs(title=unique(lpf$kb))
})
  
do.call(grid.arrange, c(plist, top='Alpha=0.5'))
```


```{r, fig.width=10,fig.height=7, eval=F}
## 0.8

loo.pred.confidence = purrr::map( list.files(data,full.names = T), function(f) {
  #print(f)
  load(paste0(f,'/loo_0.8.Rdata'),verbose=F)
  suppressWarnings(pred.conf(pg.samp)) %>% mutate(kb = basename(f))
}) 
names(loo.pred.confidence) = basename(list.files(data,full.names = T))

plist = lapply(loo.pred.confidence, function(lpf) {
  BarrettsProgressionRisk::showPredictionCalibration(lpf %>% dplyr::rename('perc' = 'P.ratio') ) + labs(title=unique(lpf$kb))
})
  
do.call(grid.arrange, c(plist, top='Alpha=0.8'))
```

## Discovery LOO alpha=0.9

```{r, fig.width=8, fig.height=12}
files = grep('supp', list.files(data,full.names = T), invert = T, value = T)
## ALL LOO is at alpha=0.9
loo.pred.confidence = purrr::map( files, function(f) {
  #print(f)
  load(paste0(f,'/loo_0.9.Rdata'),verbose=F)
  suppressWarnings(pred.conf(pg.samp)) %>% mutate(kb = basename(f))
}) 
names(loo.pred.confidence) = basename(files)

plist = lapply(loo.pred.confidence, function(lpf) {
  BarrettsProgressionRisk::showPredictionCalibration(lpf %>% dplyr::rename('perc' = 'P.ratio') ) + labs(title=unique(lpf$kb))
})

do.call(grid.arrange, c(plist[c('15kb','50kb','100kb','500kb')], top='Discovery LOO alpha=0.9'))
```

## Per-sample alpha=0.9

```{r, fig.width=8, fig.height=12}

lapply(files, function(f) {
  load(paste0(f,'/loo_0.9.Rdata'),verbose=F)
  
  kb = basename(f)
  
  pg.samp = pg.samp %>% mutate(quants = cut(Prediction, breaks=seq(0,1,0.1), include.lowest = T)) %>%
    left_join(loo.pred.confidence[[kb]] %>% dplyr::select(quants, Risk), by='quants') %>%
    mutate(Risk = factor(Risk, levels=c('Low','Moderate','High'), ordered=T))

  pg.samp %>% group_by(Status, Risk) %>% tally %>% spread(Risk,n) %>% 
    left_join(pg.samp %>% group_by(Status) %>% tally, by='Status') %>%
    dplyr::rename('Total' = 'n') %>% mutate(kb = kb)
    
}) %>% bind_rows() %>% dplyr::rename('Total samples' = 'Total') %>% write_tsv('plots/exfig10a.tsv')

per.samp.train = lapply(files, function(f) {
  load(paste0(f,'/loo_0.9.Rdata'),verbose=F)
  
  kb = basename(f)
  
  pg.samp = pg.samp %>% mutate(quants = cut(Prediction, breaks=seq(0,1,0.1), include.lowest = T)) %>%
    left_join(loo.pred.confidence[[kb]] %>% dplyr::select(quants, Risk), by='quants') %>%
    mutate(Risk = factor(Risk, levels=c('Low','Moderate','High'), ordered=T))

  pg.samp %>% group_by(Status, Risk) %>% tally %>% spread(Risk,n) %>% 
    left_join(pg.samp %>% group_by(Status) %>% tally, by='Status') %>%
    dplyr::rename('Total' = 'n') %>%
    mutate_at(vars(Low,Moderate,High), funs(./Total)) %>% mutate(kb = kb)
})
names(per.samp.train) = basename(files)

plist = purrr::map(names(per.samp.train), function(kb) {
  df = melt(per.samp.train[[kb]], id.vars=c('Status','Total','kb')) %>% as_tibble %>% mutate(Status = recode_factor(Status, NP = 'Non-Progressor', P = 'Progressor'))
  ggplot(df, aes(Status, value, group=Status, fill=variable)) + 
    ylim(0,1) + geom_bar(stat = 'identity')  + 
    geom_text(aes(label=round(value,2)), position = position_stack(vjust=0.5)) + 
    scale_fill_manual(values =  BarrettsProgressionRisk:::riskColors(), name = 'Class') +
    labs(title=unique(kb), x='', y='sample ratio') + theme_minimal() + theme(text = element_text(size = 12), legend.position = 'none')
})
names(plist) = names(per.samp.train)

p = do.call(grid.arrange, c(plist[c('15kb','50kb','100kb','500kb')], top='Discovery Cohort Classifications (alpha=0.9)'))

grid.arrange(p)

ggsave(filename='plots/parameters/kb_classes.png', plot = p, width = 6, height = 12, units = 'in', dpi = 300)


# x = do.call(bind_rows, per.samp.train) 
# x = melt(x, id.vars=c('Status','Total', 'kb')) %>% as_tibble %>% mutate(Status = recode_factor(Status, NP = 'Non-Progressor', P = 'Progressor'), kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))
#   ggplot(x, aes(Status, value, group=Status, fill=variable)) + facet_wrap(kb~Status, scale='free_x', nrow=2) + 
#     ylim(0,1) + geom_bar(stat = 'identity')  + 
#     geom_text(aes(label=round(value,2)), position = position_stack(vjust=0.5)) + 
#     scale_fill_manual(values =  BarrettsProgressionRisk:::riskColors(), name = 'Class') +
#     labs(title=unique(kb), x='', y='sample ratio') + theme_minimal() + theme(text = element_text(size = 12), legend.position = 'none')


```



## Per endoscopy
```{r, fig.width=8, fig.height=12, eval=F}

preds.per.endo = lapply(test.preds.per.kb09, function(kb) {
  endo = kb %>% separate(Path.ID, c('PID', 'Block'), '[:blank:]|_') %>% 
    group_by(Hospital.Research.ID, Status, Endoscopy.Year, PID, kb) %>% 
    mutate(Risk = factor(Risk, levels=c('Low','Moderate','High'), ordered=T)) 
  
  total.endo = endo %>% ungroup %>% dplyr::select(PID, Status) %>% distinct %>% group_by(Status) %>% tally
  endo %>% dplyr::summarise(Max.Pred = max(Prediction), Risk = max(Risk), n.samples = length(Prediction)) %>%
    group_by(kb,Status, Risk) %>% tally %>% spread(Risk,n) %>% left_join(total.endo, by='Status') %>% ungroup %>%
    mutate_if(is.numeric, funs(./n)) %>% dplyr::select(-n)
})


plist = lapply(preds.per.endo, function(kb) {
  tt = unique(kb$kb)
  kb = kb  %>% ungroup %>% dplyr::select(-kb)

  ggplot(melt(kb, id.vars=c('Status')), aes(variable, value, group=Status, fill=Status)) + ylim(0,1) + 
    geom_bar(stat='identity', position='dodge') + geom_text(aes(label=round(value,2)), position = position_dodge(width=1)) +
    labs(title=tt, x='', y='sample ratio') + theme_minimal()
})

do.call(grid.arrange, c(plist[c('50kb','100kb','15kb','500kb')], top='Predictions per endoscopy'))

```




# Validation Data

## Per sample (alpha = 0.9)

```{r, fig.width=8, fig.height=12}
val.preds = lapply(val.preds, function(kb) {
  kb %>% dplyr::select(-Risk) %>% mutate(quants = cut(Probability, breaks=seq(0,1,0.1), include.lowest = T)) %>% 
    left_join(loo.pred.confidence[[unique(kb$kb)]] %>% dplyr::select(quants, Risk), by='quants') %>%
    mutate(Risk = factor(Risk, levels=c('Low','Moderate','High'), ordered=T)) 
})


to = nrow(val.info %>% filter(Pathology == 'OAC'))
oac = do.call(bind_rows, val.preds) %>% filter(Pathology == 'OAC')

oac %>% group_by(kb, Risk) %>% tally %>% spread(Risk,n) %>% ungroup %>% mutate_all( funs(ifelse(is.na(.), 0, .)) ) %>% 
  mutate_if(is.numeric, funs(round(./to,2))) %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T)) %>% arrange(kb) %>%
  kable(caption='OAC predictions') %>% kable_styling(full_width=F)

#val.info %>% filter(Cohort != 'Old progressor scrolls' & Pathology != 'OAC') %>% group_by(Status) %>% tally

#  roc = pROC::roc(Status ~ Probability, data=val.preds$`100kb`, auc=T, ci=T, of='thresholds',transpose=T)
#  pROC::coords(roc, "best", transpose=F) %>% mutate( auc = as.numeric(pROC::auc(roc)), kb = basename(f) )


lapply(val.preds, function(kb) {
  totals = kb %>% dplyr::filter(Cohort != 'Old progressor scrolls' & Pathology != 'OAC' ) %>% group_by(Status) %>% tally
  
  kb %>% dplyr::filter(Cohort != 'Old progressor scrolls' & Pathology != 'OAC')  %>% 
    group_by(Status, Risk) %>% tally %>% spread(Risk,n) %>% ungroup %>%
    mutate(kb = unique(kb$kb)) %>% left_join(totals, by='Status')
}) %>% bind_rows() %>% dplyr::rename('Total samples' = 'n') %>% dplyr::select(kb, Status, everything()) %>% write_tsv('plots/exfig10b.tsv')
  


val.counts = lapply(val.preds, function(kb) {
  totals = kb %>% dplyr::filter(Cohort != 'Old progressor scrolls' & Pathology != 'OAC') %>% group_by(Status) %>% tally
  
  kb %>% dplyr::filter(Cohort != 'Old progressor scrolls' & Pathology != 'OAC')  %>% 
    group_by(Status, Risk) %>% tally %>% spread(Risk,n) %>% ungroup %>%
    mutate(kb = unique(kb$kb)) %>% left_join(totals, by='Status') %>% 
    mutate_if(is.numeric, funs(./n)) %>% dplyr::select(-n)
})

plist = lapply(val.counts, function(kb) {
  tt = unique(kb$kb)
  kb = kb  %>% ungroup %>% dplyr::select(-kb)
  
  ggplot(melt(kb, id.vars=c('Status')), aes(variable, value, group=Status, fill=Status)) + ylim(0,1) + 
    geom_bar(stat='identity', position='dodge') + geom_text(aes(label=round(value,2)), position = position_dodge(width=1)) +
    labs(title=tt, x='', y='ratio') + theme_minimal()
})
do.call(grid.arrange, c(plist[c('50kb','100kb','15kb','500kb')], top='Validation'))

plist = purrr::map(names(val.counts), function(kb) {
  df = melt(val.counts[[kb]], id.vars=c('Status','kb')) %>% as_tibble %>% mutate(Status = recode_factor(Status, NP = 'Non-Progressor', P = 'Progressor'))
  ggplot(df, aes(Status, value, group=Status, fill=variable)) + 
    ylim(0,1) + geom_bar(stat = 'identity')  + 
    geom_text(aes(label=round(value,2)), position = position_stack(vjust=0.5)) + 
    scale_fill_manual(values =  BarrettsProgressionRisk:::riskColors(), name = 'Class') +
    labs(title=unique(kb), x='', y='sample ratio') + theme_minimal() + theme(text = element_text(size = 12), legend.position = 'none')
})
names(plist) = names(val.counts)



p = do.call(grid.arrange, c(plist[c('15kb','50kb','100kb','500kb')], top='Validation Cohort Classifications (alpha=0.9)'))

ggsave(filename='plots/parameters/kb_val_classes.png', plot = p, width = 6, height = 12, units = 'in', dpi = 300)


```

## Per endoscopy

```{r, fig.width=8, fig.height=12}

val.endo = lapply(val.preds, function(kb) {
  endo = kb %>% dplyr::filter(Cohort != 'Old progressor scrolls' & Pathology != 'OAC') %>%
    separate(`Block ID`, c('PID','Block'), '[:blank:]|-|\\/', extra = 'drop') 
  
  total.endo = endo %>% ungroup %>% dplyr::select(PID, Status) %>% distinct %>% group_by(Status) %>% tally
    
  endo %>% group_by(`Hospital Research ID`, `PID`, Status, kb) %>%
    dplyr::summarise(Max.Prob = max(Probability), Risk = max(Risk)) %>%
    group_by(kb,Status,Risk) %>% tally %>% spread(Risk,n) %>% left_join(total.endo, by='Status') %>% ungroup %>%
    mutate_all( funs( ifelse(is.na(.), 0, .) ) ) %>%
    mutate_if(is.numeric, funs(./n)) %>% dplyr::select(-n)
})


plist = lapply(val.endo, function(kb) {
  tt = unique(kb$kb)
  kb = kb  %>% ungroup %>% dplyr::select(-kb)
  
  ggplot(melt(kb, id.vars=c('Status')), aes(variable, value, group=Status, fill=Status)) + ylim(0,1) + 
    geom_bar(stat='identity', position='dodge') + geom_text(aes(label=round(value,2)), position = position_dodge(width=1)) +
    labs(title=tt, x='', y='ratio') + theme_minimal()
})

do.call(grid.arrange, c(plist[c('50kb','100kb','15kb','500kb')], top='Validation per Endoscopy'))


```

