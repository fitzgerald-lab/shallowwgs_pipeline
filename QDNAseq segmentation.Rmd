---
title: "QDNAseq segmentation"
author: "Sarah Killcoyne"
date: "03/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(gridExtra)
library(kableExtra)
source('lib/load_patient_metadata.R')


info.file = '~/Data/BarrettsProgressionRisk/QDNAseq/training/All_patient_info.xlsx'
train.info = read.patient.info(info.file)$info

qdna.dirs = '~/Data/BarrettsProgressionRisk/Analysis/pcf_perPatient/'
train.dists.by.kb = purrr::map( list.files(qdna.dirs, full.names=T), function(dir) {
  do.call(bind_rows, lapply(list.files(dir, 'raw_dist.tsv', full.names = T, recursive = T), function(f) {
    read_tsv(f,col_types = 'ccdddddddd') %>% mutate(kb = basename(dir))  
  }))
})
names(train.dists.by.kb) = basename(list.files(qdna.dirs, full.names=T))

train.resids = purrr::map( list.files(qdna.dirs, full.names=T), function(dir) {
  do.call(bind_rows, lapply(list.files(dir, 'residuals.tsv', full.names = T, recursive = T), function(f) {
    read_tsv(f,col_types = 'ccddddl') %>% mutate(kb = basename(dir))  
  }))
})
names(train.resids) = basename(list.files(qdna.dirs, full.names=T))

train.tiles = purrr::map( list.files(qdna.dirs, full.names=T), function(dir) {
  do.call(bind_rows, lapply(list.files(dir, '5e06_tile', recursive = T, full.names = T), function(f) {
    read_tsv(f, col_types = cols( .default = col_double(), X1 = col_character())) %>% dplyr::rename(sample = 'X1') 
  }))
})
names(train.tiles) = basename(list.files(qdna.dirs, full.names=T))

val.file = '~/Data/BarrettsProgressionRisk/QDNAseq/validation/sWGS_validation_batches.xlsx'
sheets = readxl::excel_sheets(val.file)[8:14]

pastefun<-function(x) {
  if ( !grepl('SLX-', x) ) x = paste0('SLX-',x)
  return(x)
}

val.info = do.call(bind_rows, lapply(sheets, function(s) {
  readxl::read_xlsx(val.file, s) %>% dplyr::select(`Hospital Research ID`, matches('Status'), `Block ID`,`Sample Type`, `SLX-ID`, `Index Sequence`, Pathology, Cohort, Batch, matches('Collection|Notes')) %>% 
    dplyr::filter(!is.na(`SLX-ID`)) %>% mutate_at(vars(`SLX-ID`, `Block ID`), list(as.character)) 
})) %>% mutate(Samplename = paste(`SLX-ID`,`Index Sequence`, sep='.')) %>% 
  rowwise %>% mutate_at(vars(`SLX-ID`), list(pastefun) ) %>% ungroup %>% 
  mutate(
  `Hospital Research ID` = str_replace_all( str_remove_all(`Hospital Research ID`, " "), '/', '_'), 
  `Index Sequence` = str_replace_all(`Index Sequence`, 'tp', ''),
  Samplename = paste(`SLX-ID`,`Index Sequence`,sep='.')
  )


qdna.dirs = '~/Data/BarrettsProgressionRisk/Analysis/validation/pcf_perPatient'
val.dists.by.kb = purrr::map( list.files(qdna.dirs, full.names=T), function(dir) {
  do.call(bind_rows, lapply(list.files(dir, 'raw_dist.tsv', full.names = T, recursive = T), function(f) {
    read_tsv(f,col_types = 'ccdddddddd') %>% mutate(kb = basename(dir))  
  }))
})
names(val.dists.by.kb) = basename(list.files(qdna.dirs, full.names=T))


val.tiles = purrr::map( list.files(qdna.dirs, full.names=T), function(dir) {
  do.call(bind_rows, lapply(list.files(dir, '5e06_tile', recursive = T, full.names = T), function(f) {
    read_tsv(f, col_types = cols( .default = col_double(), X1 = col_character())) %>% dplyr::rename(sample = 'X1') 
  }))
})
names(val.tiles) = basename(list.files(qdna.dirs, full.names=T))


val.resids = purrr::map( list.files(qdna.dirs, full.names=T), function(dir) {
  do.call(bind_rows, lapply(list.files(dir, 'residuals.tsv', full.names = T, recursive = T), function(f) {
    read_tsv(f,col_types = 'ccddddl') %>% mutate(kb = basename(dir))  
  }))
})
names(val.resids) = basename(list.files(qdna.dirs, full.names=T))
```

# Raw Data

## Training Data

The training data was all reprocessed at different QDNAseq bin sizes

```{r}
m = melt(do.call(bind_rows, train.dists.by.kb), id.vars='kb', measure.vars=c('median'))
m = m %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))
ggplot(m, aes(kb, value, group=kb)) + geom_boxplot(aes(fill=kb), show.legend = F) + ylim(0.95,1.05) + 
  scale_fill_brewer(palette='Set1') + 
  labs(title='Training data median per QDNAseq bin size', y='median',x='') + theme_minimal()

m = melt(do.call(bind_rows, train.dists.by.kb), id.vars='kb', measure.vars=c('stdev'))
m = m %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))
ggplot(m, aes(kb, value, group=kb)) + geom_boxplot(aes(fill=kb), show.legend = F) + ylim(0,1) +
  scale_fill_brewer(palette='Set1') + 
  labs(title='Training data variance per QDNAseq bin size', y='stdev',x='') + theme_minimal()

m %>% group_by(kb) %>% dplyr::summarise( outliers = length(which(value > 1)), median.variance = median(value), min.var=min(value), max.var=max(value)) %>% mutate_if(is.numeric, list(~round(.,3))) %>%
  kable(caption='Training data variance') %>% kable_styling(full_width = F)
```


## Validation Data

The validation data was all reprocessed at different QDNAseq bin sizes

```{r}
m = melt(do.call(bind_rows, val.dists.by.kb), id.vars='kb', measure.vars=c('median'))
m = m %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))
ggplot(m, aes(kb, value, group=kb)) + geom_boxplot(aes(fill=kb), show.legend = F) + ylim(0.95,1.05) + 
  scale_fill_brewer(palette='Set1') + 
  labs(title='Validation data median per QDNAseq bin size', y='median',x='') + theme_minimal()

m = melt(do.call(bind_rows, val.dists.by.kb), id.vars='kb', measure.vars=c('stdev'))
m = m %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))
ggplot(m, aes(kb, value, group=kb)) + geom_boxplot(aes(fill=kb), show.legend = F) + ylim(0,1) +
  scale_fill_brewer(palette='Set1') + 
  labs(title='Validation data variance per QDNAseq bin size', y='stdev',x='') + theme_minimal()

m %>% group_by(kb) %>% dplyr::summarise( outliers = length(which(value > 1)), median.variance = median(value), min.var=min(value), max.var=max(value)) %>% mutate_if(is.numeric, list(~round(.,3))) %>%
  kable(caption='Validation data variance') %>% kable_styling(full_width = F)
```


## Training vs Validation

At every bin size there is an overall increase in the variance for the validation set.  It is not driven by the outliers.

```{r}
all = bind_rows(do.call(bind_rows, train.dists.by.kb) %>% mutate(cohort='training'),
                do.call(bind_rows, val.dists.by.kb) %>% mutate(cohort = 'validation'))
all = all %>% mutate(kb = factor(kb, levels=c('15kb','50kb','100kb','500kb'), ordered=T))

m = melt(all, id.vars=c('kb','cohort'), measure.vars='stdev')
ggplot(m, aes(cohort, value, group=cohort)) + facet_grid(~kb) + ylim(0,1) +
  geom_jitter(width=0.2,alpha=0.5) + geom_violin(aes(fill=kb), alpha=0.5, show.legend=F) + 
  #geom_boxplot(aes(fill=kb), outlier.color=NA, show.legend = F) 
  scale_fill_brewer(palette='Set1') + labs(title='Data variance per QDNAseq bin size', y='stdev',x='') + theme_minimal()

m = melt(all, id.vars=c('kb','cohort'), measure.vars='median')
ggplot(m, aes(cohort, value, group=cohort)) + facet_grid(~kb) + 
  geom_jitter(width=0.2,alpha=0.5) + geom_violin(aes(fill=kb), alpha=0.5, show.legend=F) + ylim(0.95,1.1) +
  scale_fill_brewer(palette='Set1') + labs(title='Median per QDNAseq bin size', y='median',x='') + theme_minimal()

ggplot(all %>% filter(kb == '100kb'), aes(stdev)) + facet_grid(~cohort) + 
  geom_density(fill='lightblue',kernel='gaussian') + xlim(0,1)

```

## Post segmentation residuals

The variance continues (as before) and is reflected in the residuals of the segmented values for each bin size

```{r}
plist = lapply(train.resids, function(df) {
  lim = c(0, max(df$varMAD_median))
  if (max(df$varMAD_median) > 0.05) lim = c(min(df$varMAD_median), 0.05)
  ggplot(df, aes(varMAD_median)) + geom_histogram(color='lightblue') + labs(title=unique(df$kb)) + xlim(lim)
})
do.call(grid.arrange, c(plist))

all.resids = bind_rows(
  do.call(bind_rows, train.resids) %>% mutate(cohort='training'),
  do.call(bind_rows, val.resids) %>% mutate(cohort='validation') )

m = melt(all.resids, id.vars=c('kb','cohort'), measure.vars = 'varMAD_median')
ggplot(m %>% filter(value < 0.1), aes(cohort, value)) + facet_grid(~kb) + 
  geom_jitter(width=0.2, alpha=0.5) + geom_violin(aes(fill=cohort), alpha=0.5, show.legend=F) + 
  labs(title='Post-segmentation MAD residuals', x='median MAD variance')


cutoffs = list('100kb' = 0.009, '15kb' = 0.011, '500kb' = 0.005, '50kb' = 0.011)

sapply(names(train.resids), function(kb) nrow( train.resids[[kb]] %>% filter(varMAD_median >= cutoffs[kb])))
sapply(names(val.resids), function(kb) nrow( val.resids[[kb]] %>% filter(varMAD_median >= cutoffs[kb])))

ggplot(do.call(bind_rows,train.resids), aes(kb, varMAD_median)) + geom_boxplot() + ylim(0,0.05)
```

## Post segmentation 5mb bins

```{r}
train.tile.var = do.call(bind_rows, lapply(train.tiles, function(df) {
  df %>% dplyr::summarise_if(is.double, list( ~ sd(.,na.rm=T) ))  
})) %>% add_column(kb  = names(train.tiles), cohort = 'training', .before=1)

val.tile.var = do.call(bind_rows, lapply(val.tiles, function(df) {
  df %>% dplyr::summarise_if(is.double, list( ~ sd(.,na.rm=T) ))  
})) %>% add_column(kb  = names(val.tiles), cohort = 'validation', .before=1)

m = melt(bind_rows(train.tile.var, val.tile.var), id.vars = c('kb','cohort'))

ggplot(m, aes(variable, value, color=cohort, group=cohort)) + ylim(0.95,1.05) + facet_grid(~kb) +  geom_jitter(position = position_dodge(width=1)) + geom_violin(position = position_dodge(width=1), alpha=0.5) 

```


### Post z-adjustment

```{r}
z.sds = lapply(train.tiles, function(df) {
  df %>% dplyr::summarise_if(is.double, list( ~ sd(.,na.rm=T) ))  
})

z.means = lapply(train.tiles, function(df) {
  df %>% dplyr::summarise_if(is.double, list( ~ mean(.,na.rm=T) ))  
})

scaled.training = lapply(train.tiles, function(df) {
  df %>% dplyr::mutate_if(is.double, list(~ BarrettsProgressionRisk:::unit.var(.) ) )
})


scaled.val = lapply(names(val.tiles), function(kb) {
  df = val.tiles[[kb]]
  zm = z.means[[kb]]
  zd = z.sds[[kb]]
  for (col in colnames((df %>% dplyr::select(-sample))))
       df[[col]] = BarrettsProgressionRisk:::unit.var( df[[col]], zm[[col]], zd[[col]]  )
  return(df)       
})
names(scaled.val) = names(val.tiles)


scale.train.tile.var = do.call(bind_rows, lapply(scaled.training, function(df) {
  df %>% dplyr::summarise_if(is.double, list( ~ median(.,na.rm=T) ))  
})) %>% add_column(kb  = names(scaled.training), cohort = 'training', .before=1)

scale.val.tile.var = do.call(bind_rows, lapply(scaled.val, function(df) {
  df %>% dplyr::summarise_if(is.double, list( ~ median(.,na.rm=T) ))  
})) %>% add_column(kb  = names(scaled.val), cohort = 'validation', .before=1)

m = melt(bind_rows(scale.train.tile.var, scale.val.tile.var), id.vars = c('kb','cohort'))

ggplot(m, aes(cohort, value, color=cohort, group=cohort)) + facet_grid(~kb) +  
  geom_jitter(position = position_dodge(width=1)) + 
  geom_violin(position = position_dodge(width=1), alpha=0.5) 


```


