---
title: "RegressionPvNP"
author: "Sarah Killcoyne"
date: "31 March 2017"
output: 
  html_document: 
    fig_caption: yes
    fig_height: 10
    fig_width: 10
    toc: yes
---

```{r setup, include=FALSE}
library(ggplot2)
library(ggfortify)
library(plyr)
library(pander)
library(Hmisc)
library(reshape2)
library(gridExtra)
library(GenomicRanges)
library(glmnet)

load('patients.Rdata', verbose=T)

source('lib/load_patient_metadata.R')

data = '~/Data/Ellie'

data.files = list.files(paste(data, 'QDNAseq',sep='/'), full.names=T)
plot.dir = paste(data, 'Analysis/multipcf_plots_fitted_perPatient', sep='/')

if (length(list.files(plot.dir)) <= 0)
  stop(paste("No analysis files found in", plot.dir ))

## Patient info file
patient.file = grep('All_patient_info.xls', data.files, value=T)
if (length(patient.file) != 1)
  stop(paste("Missing/too many patient info file(s) in", data))

patient.info = read.patient.info(patient.file)
patient.info$Patient = gsub("/", "_", patient.info$Patient)
head(patient.info)

patient.info = arrange(patient.info, Status, Patient, Endoscopy.Year, Pathology)

sum.patient.data = summarise.patient.info(patient.info)
sum.patient.data = as.data.frame(subset(sum.patient.data, Patient %in% names(patient.data))) ## For now
pander(sum.patient.data[,c('Patient', 'Status', 'start.year', 'end.year','total.samples','total.endos','highest.path')])


# Missing some of the samples as they aren't all sequenced yet
for (pt in names(patient.data)) {
  patient.data[[pt]]$info = patient.data[[pt]]$info[patient.data[[pt]]$info$Samplename %in% colnames(patient.data[[pt]]$seg.vals)[-(1:5)],]
}
```


```{r apclust-func, echo=F, message=F, warning=F}
suppressPackageStartupMessages( library(apcluster) )

apclust.data<-function(segdata, samples) {
  x1 = segdata[,intersect(colnames(segdata), samples)]
  x1 = x1[, samples]
  rownames(x1) = (segdata[,c(1:4)] %>%
    rowwise() %>%
    mutate(location=paste(paste(chrom, arm, sep=''), '.', start.pos, '-', end.pos, sep='')))$location
  return(x1)  
}

apclust<-function(segdata) {
  x1 = apclust.data(segdata)
  # q=0 minimize off-diagonal similarity
  ac = apcluster(negDistMat(r=2), x1, details=T, convits=25, q=0)
  return(list('apres'=ac, 'data'=x1))
}

net.similarity<-function(ac) {
  if (is.list(ac))
    ac = ac$apres
  ac@netsim
}

sum.similarity<-function(ac) {
  if (is.list(ac))
    ac = ac$apres
  ac@dpsim
}

clusters<-function(ac) {
  if (is.list(ac))
    ac = ac$apres
  ac@exemplars
}

plotAC<-function(aclist) {
  plot(aclist$apres, aclist$data)
} 

heatmapAC<-function(aclist) {
  heatmap(aclist$apres)
}

# First vs last samples
#x1 = apclust.data(patient.data[[pt]]$seg.vals[,c(1:4, 6, ncol(patient.data[[pt]]$seg.vals))], patient.data[[pt]]$info$Samplename)
```

The previous analysis employed AP clustering on a per-patient basis to look for evidence that it was possible to see differences between the progressors and non-progressors, and to quantify that in some sort of complexity measure.  It was able to separate them, and continued to do so after removing HGD samples, but quickly failed to model any difference as I removed timepoints from the patient.  

As suggested by Moritz it is possible to merge all of the patient samples and use GLMs to model the differences, and to select regions that may be most reflective of the differences. In this report that's what I've done, and it worked very well.  However, I'm a bit suspicious that it's worked too well.  I'm looking for biases in the data, or mistakes I might have made in setting up the model.

# Encode the large data matrix

To use GLMs across the patients I merge all samples from all patients and overlap the copy number segments. Where segments from a sample get split, the value of the original sample is retained for each of the split samples.


```{r tile, echo=F, message=F, warning=F, include=F}

chr.lengths = get.chr.lengths()
chr.lengths$chrom = sub('chr','',chr.lengths$chrom)
chr.lengths$start = 1

tile.w=1e7

genome = makeGRangesFromDataFrame(chr.lengths[1:22,], seqnames.field = 'chrom', end.field='chr.length')
tiles = tile(genome, width=tile.w)

tileFile = paste(as.character(tile.w),'_tiledpts.Rdata', sep='')
if (file.exists(tileFile)) {
  load(tileFile, verbose=T)
} else {
  grList = lapply(patient.data, function(df) {
    df$info = arrange(df$info, Endoscopy.Year, Pathology)
  
    x1 = apclust.data(df$seg.vals, df$info$Samplename)
    head(x1)
  
    segnames = as.data.frame(do.call(rbind, sapply(rownames(x1), strsplit, '[p|q].|-')))
    colnames(segnames) = c('chr','start','end')
    segnames[c('start','end')] = lapply(segnames[c('start','end')], function(x) as.numeric(as.character(x)))
  
    pt = unique(df$info$Patient)
    return( makeGRangesFromDataFrame(cbind(segnames,pt, x1), keep.extra.columns = T) )
  })
  
  sampleNames = unlist(sapply(patient.data, function(df) {
    df$info = arrange(df$info, Endoscopy.Year, Pathology)
    x1 = apclust.data(df$seg.vals, df$info$Samplename)
    colnames(x1)
  }))
  
  tile.segments<-function(tiles, gr, mergedSegments) {
    ov = findOverlaps(tiles, gr)
    for (qh in unique(queryHits(ov))) {
      print(qh)
      currentTile = tiles[[qh]]
      curov = findOverlaps(currentTile, gr)
    
      for (i in 1:length(curov)) {
        segment = currentTile[ queryHits(curov)[i]  ]
        #print(segment)
        rows = with(mergedDf, which( chr==as.character(seqnames(segment)) & start == start(segment) & end == end(segment)))
        segmentVals = as.data.frame(elementMetadata(gr[ subjectHits(curov)[i] ]))
        mergedSegments[rows, names(segmentVals)[-1]] = segmentVals[,-1]
      }
    }
    return(mergedSegments)  
  }
  
  mergedDf = do.call(rbind, lapply(tiles, function(tile) { 
    cbind('chr'=as.character(seqnames(tile)), as.data.frame(ranges(tile))[1:2]) 
    }) )
  mergedDf[,sampleNames] = NA
    
  for (gr in grList) {
    print(unique(gr$pt))
    mergedDf = tile.segments(tiles, gr, mergedDf)
  }
  
  #tmp = mergedDf
  mergedDf[is.na(mergedDf)] = 0
  rownames(mergedDf) = with(mergedDf, paste(chr, ':', start, '-', end, sep=''))
  
  save(mergedDf, file=tileFile)
}


```

Using a very large segment size for tiling across all patients (`r tile.w`) I get the following binomial models.  None of them fit well, and decreasing the size of the segments results in poor (or no) fits with mostly NA coefficients, or a lot of P(0 or 1).

# y = Progressors (1) vs Non (0)

The labels are split such that all samples from progressor patients are (1) and all samples from non-progressors are (0).

```{r labelsPNP, echo=F, message=F, include=F}
## binomial: dysplasia 1, BE 0

labels = unlist(sapply(patient.data, function(df) {
  df$info = arrange(df$info, Endoscopy.Year, Pathology)
  label = as.integer(df$info$Status == 'P') #as.integer(df$info$Pathology %in% c('HGD', 'IMC'))
  names(label) = df$info$Samplename
  return(label)
}))
names(labels) = sub('.*\\.', '',  names(labels))

pts = do.call(rbind, lapply(patient.data, function(df) {
  df$info = arrange(df$info, Endoscopy.Year, Pathology)
  cbind(df$info[,c('Patient','Samplename')])
}))
rownames(pts) = 1:nrow(pts)

# sort in label order
if (length(setdiff(colnames(mergedDf), names(labels))) > 3)
  warning("Labels vector is missing samples")

dysplasia.df = t(mergedDf[,names(labels)])
```

We have `r table(labels)[1]` samples from non-progressors and `r table(labels)[2]` samples from progressors.

Data matrix currently:
`r pander(dysplasia.df[1:10, 1:5], caption=paste("dimensions:", paste(dim(dysplasia.df), collapse=', ')), justify='left')`

## cv.glmnet Ridge vs Lasso

With all `r ncol(dysplasia.df)` regions of the genome, first check if/which regression may be appropriate. It appears that pure lasso may provide the best balance for number of features with non-zero coefficients.

```{r cvglmnetPNP, echo=F, warning=F, message=F}
plot.multi.cv.glmnet<-function(x,y,alpha=c(0,1), family="binomial", title='cv.glmnet') {
  plots <- list(  )
  cv.models = data.frame(matrix(ncol=3,nrow=0,dimnames=list(c(), c('class','lambda','cvm'))))
  for (a in alpha) {
    cv = cv.glmnet(x, y, alpha=a, family=family, standardize=F)
    cv.models = rbind(cv.models, cbind('class'=paste('cv',a,sep=''), 'lambda'=log(cv$lambda), 'cvm'=cv$cvm))
    plots[[as.character(a)]] = autoplot(cv, main=paste('alpha',a), ylab=cv$name)
  }
  cv.models[c('lambda','cvm')] = lapply(cv.models[c('lambda','cvm')], function(x) as.numeric(as.character(x)))
  
  gg = ggplot(cv.models, aes(x=lambda, y=cvm, color=class)) + geom_point() + geom_line() + 
      labs(x='log(Lambda)', y='Binomial Deviance', title=title)
  
  plots[['all']] = gg
  
  return(plots)
}

gp = plot.multi.cv.glmnet(dysplasia.df, labels, alpha=c(0,0.5,0.8,1), title='cv.glmnet P vs NP')

cv1 = cv.glmnet(dysplasia.df, labels, alpha=1, family='binomial')
gg = autoplot(cv1$glmnet.fit, xvar='lambda', main='alpha=1 glmnet.fit from cv.glmnet') + theme(legend.position='none') 

gp[['coef.1']] = gg

do.call(grid.arrange, c(gp, ncol=2, nrow=3))

```

## xval by patients

Split into 5ths by patient, fit and predict at each split, select min lambda, get coefficients from the initial model using that value.

```{r xvalpt, message=F, warning=F, echo=F, fig.height=6, fig.width=6}
precisionRecall<-function(actual, predicted) { ## needs to calculate for both 0 and 1
    retrieved <- sum(predicted==1)
    recall <- sum(predicted==1 & actual==1) / sum(actual==1)
    sum(predicted==0 & actual==0) / sum(actual==0)
    
    precision <- sum(predicted==1 & actual==1) / retrieved
    f1 = signif(2*(1/(1/precision+1/recall)), 2)
    return(data.frame('precision'=precision, 'recall'=recall, 'F1'=signif(f1, 2)))
}



pi.hat<-function(x) exp(x)/(1+exp(x))

non.zero.coef<-function(fit, s) {
  cf =  as.matrix(coef(fit, s))
  cf[which(cf != 0),][-1]
}

cv.patient.glmnet<-function(x,y,lambda,pts) {
  message(paste("Running", length(unique(pts$group)), "folds"))
  
  cv.class = matrix(nrow=5, ncol=length(lambda))
  f1 = matrix(nrow=5, ncol=length(lambda))
  prec = f1; recall = f1

  fit.e = list()
  for (i in 1:length(unique(patients$group))) {  ## This is not stable. 
    message(paste(i, "fold"))
    test.rows = which(rownames(x) %in% subset(pts, group == i)$Samplename)
    test = x[test.rows,]
    training = x[-test.rows,]
    # pre-spec lambda seq
    fit <- glmnet(training, y[-test.rows], lambda=lambda, family='binomial', alpha=1) 
    # autoplot(fit) + theme(legend.position="none")
    
    pred.class <- predict(fit, test, type='class') # check this later


    proc = do.call(rbind, apply(pred.class, 2, function(pd) {
      if (sum(as.numeric(pd)) <= 0) return(0)
      #as.numeric(pROC::auc(pROC::roc(response=as.numeric(pd), predictor=labels[test.rows])))  
      precisionRecall(labels[test.rows], as.numeric(pd))
    }))

    f1[i,] = proc$F1
    prec[i,] = proc$precision
    recall[i,] = proc$recall
    
    # careful: matrix
    pred <- pi.hat(predict(fit, test)) 
    cv.class[i,] = apply(pred, 2, function(p) {
      # Confusion matrix
       #cmat = table(labels[test.rows], p>0.5)
       #sum(diag(cmat))/sum(cmat)
      # quantitiative, pos results + neg results / number of test rows
      (p%*%labels[test.rows] + (1-p) %*% (1-labels[test.rows]))/ length(test.rows)
    })
    
    fit.e[[i]] = fit
  }

  df = cbind.data.frame('lambda.at'=1:ncol(cv.class),'mean'=colMeans(cv.class), 
                        'sme'=apply(cv.class, 2, sd)/5, 
                        'sd'=apply(cv.class, 2, sd), 
                        'lambda'=lambda)

  lambda.opt = lambda[which.max(df$mean)-1]
  nzcf = lapply(fit.e, non.zero.coef, s=lambda.opt)
  
  gp = ggplot(df, aes(y=mean,x=lambda.at)) + geom_point() + 
          geom_errorbar(aes(ymin=mean-sme, ymax=mean+sme)) + labs(y='mean of confusion matrix (P)') +
          geom_point(data=subset(df, mean == max(mean)), aes(y=mean, x=lambda.at, colour="max"), size=3 ) +
          geom_point(data=df[which.max(df$mean)+1,], aes(y=mean, x=lambda.at, colour="max+1"), size=3) +
          geom_point(data=df[which.max(df$mean)-1,], aes(y=mean, x=lambda.at, colour="max-1"), size=3) +
          geom_hline(yintercept=df[which.max(df$mean)-1,'mean'], colour='grey') +
          annotate("text", x=5, y=max(df$mean)+0.005, label=round(df[which.max(df$mean)-1,'mean'],2)) +
          annotate("text", x=6, y=max(df$mean)-0.005, label=round(median(df$sme),4)) +
          theme(axis.title.x = element_text(size = 15, vjust=-.2)) + scale_colour_discrete(name = "Best lambda values") +
          labs(title="CV Performance")

  return(list('max.cm'=df[which.max(df$mean)-1,'mean'], 'f1'=mean(f1[,which.max(df$mean)-1]), 'precision'=mean(prec[,which.max(df$mean)-1]), 'recall'=mean(recall[,which.max(df$mean)-1]),
              'lambda.opt'=lambda.opt, 'lambdas'=df, 'plot'=gp, 'non.zero.cf'=nzcf))
}

fit0 <- glmnet(dysplasia.df, labels, alpha = 1) # all patients
autoplot(fit0, xvar='lambda', main='fit0, all samples') + theme(legend.position='none') 
lambda <- fit0$lambda

# split patients in 5ths
s = {set.seed(2); sample(rep(seq(5), length = length(unique(pts$Patient))))}
patients = merge(pts, cbind('Patient'=unique(pts$Patient), 'group'=s), by="Patient")

# This just makes sure the sets don't become too unbalanced with regards to the labels.
sets = table(cbind(patients, labels[patients$Samplename])[,c(3:4)])
while (length(which(sets/rowSums(sets) < 0.35)) >= 2 | length(which(sets/rowSums(sets) == 0)) > 0 ) {
  print(".")
  s = sample(rep(seq(5), length = length(unique(pts$Patient))))
  patients = merge(pts, cbind('Patient'=unique(pts$Patient), 'group'=s), by="Patient")
  sets = table(cbind(patients, labels[patients$Samplename])[,c(3:4)])
}

cv.patient = cv.patient.glmnet(x=dysplasia.df, y=labels, lambda, patients)
lambda.opt = cv.patient$lambda.opt

coef.opt = as.data.frame(non.zero.coef(fit0, lambda.opt))

grid.arrange(cv.patient$plot + ggtitle(paste("CV Performance, 5-fold xval. mean f1 at opt lambda:", cv.patient$f1)))

## check how often the feature(s) is selected at that lamda in each split. "stability selection"
coef.stability<-function(opt, nz.list) {
  for (i in 1:length(nz.list)) {
    df = as.data.frame(nz.list[[i]])
    colnames(df) = i
    opt = merge(opt, df, by='row.names', all.x=T)
    rownames(opt) = opt$Row.names
    opt$Row.names = NULL
    opt[,(i+1)] = as.integer(!is.na(opt[,(i+1)]))
  }
  opt = opt[order(sapply(rownames(opt), function(x) as.numeric(unlist(strsplit(x, ':'))[1])  )),]
  return(opt)
}

coef.opt.stability = coef.stability(coef.opt, cv.patient$non.zero.cf)

```

`r pander(coef.opt, justify='left', caption='Features from the glm fitted with all data. Each numbered column indicates if the feature was identified in that split.')`

At a the minimum lambda-1se (green dot) the value is `r signif(lambda.opt, 3)`. In the initial model `r length(coef.opt)` coefficients have a non-zero value.  

### Feature stability

`r length(which(rowSums(coef.opt.stability[,2:6])>= 3))` features are stable in 3:5 splits

`r length(which(rowSums(coef.opt.stability[,2:6])>= 4))` features are stable in 4:5 splits

`r length(which(rowSums(coef.opt.stability[,2:6])>= 5))` features are stable in 5:5 splits

Optimal model?
```{r}

gfit = glm(labels~.,data=cbind.data.frame(dysplasia.df[,names(non.zero.coef(fit0, lambda.opt))], labels), family=binomial(link='logit'))
autoplot(gfit)

```



### Remove HGD/IMC Samples

Just as a point, the initial model is tested against `r nrow(dysplasia.df)` samples with `r ncol(dysplasia.df)` features.  

```{r noHGD, echo=F, message=F, warning=F}
`%nin%` <- Negate(`%in%`)

info = do.call(rbind, lapply(patient.data, function(df) df$info))

samples = intersect(rownames(dysplasia.df), subset(info, Pathology %nin% c('HGD', 'IMC'))$Samplename)

cv.nohgd = cv.patient.glmnet(x=dysplasia.df[samples,], y=labels[samples], lambda, subset(patients, Samplename %in% samples))
#lambda.opt = cv.patient$lambda.opt
grid.arrange(cv.nohgd$plot + ggtitle(paste("CV Performance, No HGD/IMC samples. mean f1:", cv.nohgd$f1)))
nohgd.stab = coef.stability(coef.opt, cv.nohgd$non.zero.cf)


samples = intersect(rownames(dysplasia.df), subset(info, Pathology %nin% c('HGD', 'IMC', 'LGD'))$Samplename)
cv.nolgd = cv.patient.glmnet(x=dysplasia.df[samples,], y=labels[samples], lambda, subset(patients, Samplename %in% samples))
grid.arrange(cv.nolgd$plot + ggtitle(paste("CV Performance, No HGD/IMC/LGD samples. mean f1:", cv.nohgd$f1)))
nolgd.stab = coef.stability(coef.opt, cv.nolgd$non.zero.cf)

```

#### No HGD feature stability

`r length(which(rowSums(nohgd.stab[,2:6])>= 3))` features are stable in 3:5 splits

`r length(which(rowSums(nohgd.stab[,2:6])>= 4))` features are stable in 4:5 splits

`r length(which(rowSums(nohgd.stab[,2:6])>= 5))` features are stable in 5:5 splits

#### No LGD feature stability

`r length(which(rowSums(nolgd.stab[,2:6])>= 3))` features are stable in 3:5 splits

`r length(which(rowSums(nolgd.stab[,2:6])>= 4))` features are stable in 4:5 splits

`r length(which(rowSums(nolgd.stab[,2:6])>= 5))` features are stable in 5:5 splits



### Leave one patient out

```{r loop, echo=F, message=F, warning=F, fig.height=40, fig.width=30}
fpr = data.frame(matrix(ncol=5,nrow=0))
# Randomize patients
pt.samp = sample(sum.patient.data$Patient)

#plots = list()

for (pt in pt.samp) {
  samples = as.vector(unlist(lapply(patient.data[subset(sum.patient.data, Patient != pt)$Patient], function(pt) pt$info$Samplename)))
  
  cv.back = cv.patient.glmnet(x=dysplasia.df[samples,], y=labels[samples], lambda, subset(patients, Samplename %in% samples))
#  print(median(cv.back$lambdas$sme))
 # print( paste(cv.back$f1, cv.back$precision) )
   fpr = rbind(fpr, c(cv.back$max.cm, cv.back$f1, cv.back$precision, cv.back$recall, length(samples)))
 
#  plots[[ pt ]] = cv.back$plot + ggtitle(paste("# Samples:", length(samples))) + theme(legend.position = "none")
}
colnames(fpr) = c('performance','f1','prec','recall','n.samples')

ggplot(fpr, aes(performance, f1)) + 
  geom_point() + 
  ylim(0,1) + xlim(0,1) + labs(title="LOO (patient)", x='CV Performance', y='f1 statistic')

```


## Peel back timepoints

```{r, echo=F, message=F, warning=F}
get.next.samples<-function(patient.data, i) {
  as.vector(unlist(sapply(patient.data, function(pd) {
    j = i
    pd$info = arrange(pd$info, Endoscopy.Year, Pathology)
  
    if (j >= nrow(pd$info)) j = nrow(pd$info)
    
    pd$info[1:(nrow(pd$info)-j), 'Samplename']
  }) ))
}

#subset(sum.patient.data, Status == 'P' & total.endos >= 8)

#cv.back = cv.patient.glmnet(x=dysplasia.df[samples,], y=labels[samples], lambda, subset(patients, Samplename %in% samples))
#print(cv.back$f1)

nonps = get.next.samples(patient.data[subset(sum.patient.data, Status == 'NP')$Patient], 0)
#plots = list()
fpr = data.frame(matrix(ncol=4,nrow=0))
for (i in c(0,1,seq(2,25,3))) {
  ps = get.next.samples(patient.data[subset(sum.patient.data, Status == 'P')$Patient], i)
  samples = get.next.samples(patient.data, i)
  #samples = c(nonps, ps)
  cv.back = cv.patient.glmnet(x=dysplasia.df[samples,], y=labels[samples], lambda, subset(patients, Samplename %in% samples))
  print( paste(cv.back$f1, cv.back$precision) )
  fpr = rbind(fpr, c(cv.back$f1, cv.back$precision, cv.back$recall, length(ps)))
#  plots[[ as.character(i) ]] = cv.back$plot + ggtitle(paste(length(ps), "progressor samples. mean f1:", cv.back$f1))
}
colnames(fpr) = c('f1','prec','recall','n.samples')
pander(fpr[1:5,], justify='left')
#do.call('grid.arrange', c(plots, ncol=2, top="Peeling back timepoints in progressors"))


ps = get.next.samples(patient.data[subset(sum.patient.data, Status == 'P')$Patient], 11)
samples = c(nonps, ps)
  cv.back = cv.patient.glmnet(x=dysplasia.df[samples,], y=labels[samples], lambda, subset(patients, Samplename %in% samples))
  print(median(cv.back$lambdas$sme))
  cv.back$plot + ggtitle(paste("CV Performance - ", length(ps), "progressor samples"))

info = subset(patient.info, Samplename %in% samples)
head(info)

pander(summarise.patient.info(subset(info, Status == 'P'))[,c(1:7)], justify='left')

coef.opt.stability = coef.stability(coef.opt, cv.back$non.zero.cf)

pander(coef.opt.stability[which(rowSums(coef.opt.stability[,2:6]) > 0),], justify='left', caption="Features initially identified that also are found in the subset of samples")

```



